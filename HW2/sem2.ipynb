{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DUotKHRULVPD"
   },
   "source": [
    "# Инструменты для работы с языком "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8ba5Z02VLVPK"
   },
   "source": [
    "## Задача: классификация твитов по тональности\n",
    "\n",
    "У нас есть датасет из твитов, про каждый указано, как он эмоционально окрашен: положительно или отрицательно. Задача: предсказывать эмоциональную окраску.\n",
    "\n",
    "Скачиваем куски датасета ([источник](http://study.mokoron.com/)): [положительные](https://www.dropbox.com/s/fnpq3z4bcnoktiv/positive.csv?dl=0), [отрицательные](https://www.dropbox.com/s/r6u59ljhhjdg6j0/negative.csv)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2zHB70n5LVPN",
    "outputId": "76e9cc41-c912-464c-a06e-e02879e69c08",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-09-09 13:19:11--  https://www.dropbox.com/s/fnpq3z4bcnoktiv/positive.csv\n",
      "Resolving www.dropbox.com (www.dropbox.com)... 162.125.5.18, 2620:100:601d:18::a27d:512\n",
      "Connecting to www.dropbox.com (www.dropbox.com)|162.125.5.18|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: /s/raw/fnpq3z4bcnoktiv/positive.csv [following]\n",
      "--2021-09-09 13:19:11--  https://www.dropbox.com/s/raw/fnpq3z4bcnoktiv/positive.csv\n",
      "Reusing existing connection to www.dropbox.com:443.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://uc5deaa7342fe3c977037b52e2c5.dl.dropboxusercontent.com/cd/0/inline/BV1Xadxu3n1IXx9tmNqkzNsyPqTH-qiWf5Nfv32dKnJMwKD6OI69u7qmIKkNKhRIrc-9SGTT9iC0dN2VgIBK9tGL7I5hX4G3LAlD7QVGEomgnpPVlkLWcmcvEX1u3RkqKxwuHAbN9k67C60YDA3Gjv_H/file# [following]\n",
      "--2021-09-09 13:19:11--  https://uc5deaa7342fe3c977037b52e2c5.dl.dropboxusercontent.com/cd/0/inline/BV1Xadxu3n1IXx9tmNqkzNsyPqTH-qiWf5Nfv32dKnJMwKD6OI69u7qmIKkNKhRIrc-9SGTT9iC0dN2VgIBK9tGL7I5hX4G3LAlD7QVGEomgnpPVlkLWcmcvEX1u3RkqKxwuHAbN9k67C60YDA3Gjv_H/file\n",
      "Resolving uc5deaa7342fe3c977037b52e2c5.dl.dropboxusercontent.com (uc5deaa7342fe3c977037b52e2c5.dl.dropboxusercontent.com)... 162.125.5.15, 2620:100:601d:15::a27d:50f\n",
      "Connecting to uc5deaa7342fe3c977037b52e2c5.dl.dropboxusercontent.com (uc5deaa7342fe3c977037b52e2c5.dl.dropboxusercontent.com)|162.125.5.15|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 26233379 (25M) [text/plain]\n",
      "Saving to: ‘positive.csv.1’\n",
      "\n",
      "positive.csv.1      100%[===================>]  25.02M  36.6MB/s    in 0.7s    \n",
      "\n",
      "2021-09-09 13:19:12 (36.6 MB/s) - ‘positive.csv.1’ saved [26233379/26233379]\n",
      "\n",
      "--2021-09-09 13:19:12--  https://www.dropbox.com/s/r6u59ljhhjdg6j0/negative.csv\n",
      "Resolving www.dropbox.com (www.dropbox.com)... 162.125.5.18, 2620:100:601d:18::a27d:512\n",
      "Connecting to www.dropbox.com (www.dropbox.com)|162.125.5.18|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: /s/raw/r6u59ljhhjdg6j0/negative.csv [following]\n",
      "--2021-09-09 13:19:13--  https://www.dropbox.com/s/raw/r6u59ljhhjdg6j0/negative.csv\n",
      "Reusing existing connection to www.dropbox.com:443.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://uc838e6b89a07842290da0687fae.dl.dropboxusercontent.com/cd/0/inline/BV0Pw2y7ortaXGYjatS0NSQf_xb4YoXKvvGdIBi3ixd6toR9nbBxMc7m_3Q7ikKENy-U9Tja--ZSBpqD8jijF9BSCVikBmX9Emyt2QKKw1x9-b2EIPBny9Jf4JjCB_CPIndruFlGCgUbEatngVE9XASR/file# [following]\n",
      "--2021-09-09 13:19:13--  https://uc838e6b89a07842290da0687fae.dl.dropboxusercontent.com/cd/0/inline/BV0Pw2y7ortaXGYjatS0NSQf_xb4YoXKvvGdIBi3ixd6toR9nbBxMc7m_3Q7ikKENy-U9Tja--ZSBpqD8jijF9BSCVikBmX9Emyt2QKKw1x9-b2EIPBny9Jf4JjCB_CPIndruFlGCgUbEatngVE9XASR/file\n",
      "Resolving uc838e6b89a07842290da0687fae.dl.dropboxusercontent.com (uc838e6b89a07842290da0687fae.dl.dropboxusercontent.com)... 162.125.5.15, 2620:100:601d:15::a27d:50f\n",
      "Connecting to uc838e6b89a07842290da0687fae.dl.dropboxusercontent.com (uc838e6b89a07842290da0687fae.dl.dropboxusercontent.com)|162.125.5.15|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 24450101 (23M) [text/plain]\n",
      "Saving to: ‘negative.csv.1’\n",
      "\n",
      "negative.csv.1      100%[===================>]  23.32M  42.8MB/s    in 0.5s    \n",
      "\n",
      "2021-09-09 13:19:14 (42.8 MB/s) - ‘negative.csv.1’ saved [24450101/24450101]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# если у вас линукс / мак / collab или ещё какая-то среда, в которой работает wget, можно так:\n",
    "!wget https://www.dropbox.com/s/fnpq3z4bcnoktiv/positive.csv\n",
    "!wget https://www.dropbox.com/s/r6u59ljhhjdg6j0/negative.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "J5YiZNCPLVPe"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "DFLtXAZ-LVPq"
   },
   "outputs": [],
   "source": [
    "# считываем данные и заполняем общий датасет\n",
    "positive = pd.read_csv('positive.csv', sep=';', usecols=[3], names=['text'])\n",
    "positive['label'] = ['positive'] * len(positive)\n",
    "negative = pd.read_csv('negative.csv', sep=';', usecols=[3], names=['text'])\n",
    "negative['label'] = ['negative'] * len(negative)\n",
    "df = positive.append(negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 203
    },
    "id": "j1AEISlBLVP0",
    "outputId": "443eadf2-9df4-4507-f2a5-a64f7968182f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>111918</th>\n",
       "      <td>Но не каждый хочет что то исправлять:( http://...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111919</th>\n",
       "      <td>скучаю так :-( только @taaannyaaa вправляет мо...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111920</th>\n",
       "      <td>Вот и в школу, в говно это идти уже надо(</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111921</th>\n",
       "      <td>RT @_Them__: @LisaBeroud Тауриэль, не грусти :...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111922</th>\n",
       "      <td>Такси везет меня на работу. Раздумываю приплат...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text     label\n",
       "111918  Но не каждый хочет что то исправлять:( http://...  negative\n",
       "111919  скучаю так :-( только @taaannyaaa вправляет мо...  negative\n",
       "111920          Вот и в школу, в говно это идти уже надо(  negative\n",
       "111921  RT @_Them__: @LisaBeroud Тауриэль, не грусти :...  negative\n",
       "111922  Такси везет меня на работу. Раздумываю приплат...  negative"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "ZWta7oDgLVP8"
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(df.text, df.label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tAapBC7VLVQC"
   },
   "source": [
    "## Baseline: классификация необработанных n-грамм\n",
    "\n",
    "### Векторизаторы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "M-AvVt8XLVQD"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression # можно заменить на любимый классификатор\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GSuoVoxcLVQI"
   },
   "source": [
    "Что такое n-граммы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "zeNA7732LVQJ"
   },
   "outputs": [],
   "source": [
    "from nltk import ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NeApDOmrLVQN",
    "outputId": "d8c763fe-2658-47ac-fcee-5b7bbe49f0d0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Если',), ('б',), ('мне',), ('платили',), ('каждый',), ('раз',)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = 'Если б мне платили каждый раз'.split()\n",
    "list(ngrams(sent, 1)) # униграммы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OPAS0fS-LVQQ",
    "outputId": "aa3ae031-c661-4639-b7ab-f93ba1b6cee5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Если', 'б'),\n",
       " ('б', 'мне'),\n",
       " ('мне', 'платили'),\n",
       " ('платили', 'каждый'),\n",
       " ('каждый', 'раз')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(ngrams(sent, 2)) # биграммы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d77jmVPhLVQU",
    "outputId": "c8de801b-8efc-437e-8673-4e9e31665ea5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Если', 'б', 'мне'),\n",
       " ('б', 'мне', 'платили'),\n",
       " ('мне', 'платили', 'каждый'),\n",
       " ('платили', 'каждый', 'раз')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(ngrams(sent, 3)) # триграммы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5xXTBrGELVQX",
    "outputId": "f5b423d9-db6b-4efa-8bfa-a446a55ee018"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Если', 'б', 'мне', 'платили', 'каждый'),\n",
       " ('б', 'мне', 'платили', 'каждый', 'раз')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(ngrams(sent, 5)) # ... пентаграммы?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eHGJBEm-LVQb"
   },
   "source": [
    "Самый простой способ извлечь фичи из текстовых данных -- векторизаторы: `CountVectorizer` и `TfidfVectorizer`\n",
    "\n",
    "Объект `CountVectorizer` делает простую вещь:\n",
    "* строит для каждого документа (каждой пришедшей ему строки) вектор размерности `n`, где `n` -- количество слов или n-грам во всём корпусе\n",
    "* заполняет каждый i-тый элемент количеством вхождений слова в данный документ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "eMqZFBTgLVQb"
   },
   "outputs": [],
   "source": [
    "vec = CountVectorizer(ngram_range=(1, 1))\n",
    "bow = vec.fit_transform(x_train) # bow -- bag of words (мешок слов)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AZkpqVtILVQe"
   },
   "source": [
    "ngram_range отвечает за то, какие n-граммы мы используем в качестве фичей:<br/>\n",
    "ngram_range=(1, 1) -- униграммы<br/>\n",
    "ngram_range=(3, 3) -- триграммы<br/>\n",
    "ngram_range=(1, 3) -- униграммы, биграммы и триграммы.\n",
    "\n",
    "В vec.vocabulary_ лежит словарь: мэппинг слов к их индексам:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hWRtOSzKLVQf",
    "outputId": "668857b0-def2-4547-8fd5-014fe3858bec"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('блин', 106258),\n",
       " ('обожаю', 170958),\n",
       " ('просто', 197276),\n",
       " ('когда', 146071),\n",
       " ('только', 222407),\n",
       " ('загрузишь', 133530),\n",
       " ('фильм', 230759),\n",
       " ('опера', 173818),\n",
       " ('такая', 219653),\n",
       " ('ну', 169467)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(vec.vocabulary_.items())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hkmX3iBbLVQi",
    "outputId": "5bbb432e-1c45-422a-edc2-60841ef0ee33"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=42)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(bow, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bJ8q5_59LVQm",
    "outputId": "d88c6de2-640a-4cc9-ae95-29fe12c80131"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.76      0.76      0.76     27982\n",
      "    positive       0.77      0.77      0.77     28727\n",
      "\n",
      "    accuracy                           0.76     56709\n",
      "   macro avg       0.76      0.76      0.76     56709\n",
      "weighted avg       0.76      0.76      0.76     56709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = clf.predict(vec.transform(x_test))\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QAhgaYgqLVQp"
   },
   "source": [
    "Попробуем сделать то же самое для триграмм:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GPWXlh6ALVQq",
    "outputId": "094a7189-bc36-42df-81ee-f599a206ca0c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.46      0.71      0.56     18276\n",
      "    positive       0.82      0.61      0.70     38433\n",
      "\n",
      "    accuracy                           0.64     56709\n",
      "   macro avg       0.64      0.66      0.63     56709\n",
      "weighted avg       0.70      0.64      0.65     56709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vec = CountVectorizer(ngram_range=(3, 3))\n",
    "bow = vec.fit_transform(x_train)\n",
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(bow, y_train)\n",
    "pred = clf.predict(vec.transform(x_test))\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dnfyJkzTLVQu"
   },
   "source": [
    "(как вы думаете, почему в результатах теперь такой разброс по сравнению с униграммами?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gJABxhalLVQu"
   },
   "source": [
    "## TF-IDF векторизация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-LJES2s-LVQv"
   },
   "source": [
    "`TfidfVectorizer` делает то же, что и `CountVectorizer`, но в качестве значений – tf-idf каждого слова.\n",
    "\n",
    "Как считается tf-idf:\n",
    "\n",
    "TF (term frequency) – относительная частотность слова в документе:\n",
    "$$ TF(t,d) = \\frac{n_t}{\\sum_k n_k} $$\n",
    "\n",
    "`t` -- слово (term), `d` -- документ, $n_t$ -- количество вхождений слова, $n_k$ -- количество вхождений остальных слов\n",
    "\n",
    "IDF (inverse document frequency) – обратная частота документов, в которых есть это слово:\n",
    "$$ IDF(t, D) = \\mbox{log} \\frac{|D|}{|{d : t \\in d}|} $$\n",
    "\n",
    "`t` -- слово (term), `D` -- коллекция документов\n",
    "\n",
    "Перемножаем их:\n",
    "$$TFIDF_(t,d,D) = TF(t,d) \\times IDF(i, D)$$\n",
    "\n",
    "Сакральный смысл – если слово часто встречается в одном документе, но в целом по корпусу встречается в небольшом \n",
    "количестве документов, у него высокий TF-IDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "FmEcRD28LVQ0"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AWLhMl9xLVQ3",
    "outputId": "054e5662-1c41-42f6-92e4-ce0194317ce8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.77      0.75     26705\n",
      "    positive       0.78      0.75      0.77     30004\n",
      "\n",
      "    accuracy                           0.76     56709\n",
      "   macro avg       0.76      0.76      0.76     56709\n",
      "weighted avg       0.76      0.76      0.76     56709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vec = TfidfVectorizer(ngram_range=(1, 1))\n",
    "bow = vec.fit_transform(x_train)\n",
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(bow, y_train)\n",
    "pred = clf.predict(vec.transform(x_test))\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HTODTRnKLVQ6"
   },
   "source": [
    "В этот раз получилось хуже :( Вернёмся к `CountVectorizer`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j8v9Scpn9Y0M"
   },
   "source": [
    "## PMI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WVRqLcSY0etj"
   },
   "source": [
    "Можно оценить взаимосвязь слов в корпусе и понять, какие биграммы наиболее часто встречаются в тексте. Для этого можно использовать метрику PMI (Pointwise Mutual Information) - поточечная взаимная информация. Метрика PMI для двух слов вычисляется по формуле:\n",
    "\n",
    "$$pmi(x; y) = log \\frac{p(x,y)}{p(x)p(y)} $$\n",
    "\n",
    "Здесь p(y|x) - вероятность встретить слово $y$ после $x$, $p(y)$ - вероятность встретить слово $y$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WXgDwf6W6Kk5"
   },
   "source": [
    "Оценим важность биграмм в нашем обучающем корпусе."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LKmiOEaW53F9",
    "outputId": "96a85968-e0cb-4b17-cd62-bc3de5e3e9b3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package genesis to\n",
      "[nltk_data]     C:\\Users\\Илья\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\genesis.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'nltk.corpus.reader.util.StreamBackedCorpusView'>\n",
      "[('+1239', '728'), ('+Никита', '=полностью'), ('+СОННО', '+НЕ'), ('+живіт', 'болить.ну'), (',Дела', 'рез'), ('-/////', 'прбрм-прбрм'), ('-10,11', 'болсо'), ('-163', '-КРАСНЫЙ'), ('-700', 'рублей.-А'), ('-800', 'нахууй'), ('-АХАХАХАХ', 'ЮБКУ'), ('-АХАХАХАХХАХАХАХАХАХХА', '-АХАХАХХАХАХАХАХАХ'), ('-Алина', '-Синие'), ('-Аха', 'спетросянил'), ('-Без', 'презерватива'), ('-ВАХАХАХА', 'СТИПЕНДИЯ'), ('-ВСЕМ', 'СПОКОЙНЫХ'), ('-Весело', 'кншн:3'), ('-Время', 'эмокора'), ('-Д-Д-Д-Д-Д-Д-ДРОП', 'ЗЭ'), ('-ДЕТЕЙ', 'НАКРЫЛО'), ('-ДОВАЙТИ', 'АЛДСКУЛ'), ('-Дирол', 'Сенсес'), ('-Домашка', '-кл.час'), ('-ЖАРЕНЫЙ', 'КАРТОФЕЛЬ'), ('-Зелено-карие', '-Киллджой'), ('-КРАСНЫЙ', '-ЧЕРНЫЕ'), ('-Киллджой', '-Котик'), ('-Корнейчук', 'затроллила'), ('-Маладец', '-Лол'), ('-НА', 'РЕАЛЬНЫХ'), ('-НАЧИНАЕТ', 'БЕСИТЬ'), ('-ОЗВУЧИВАТЕЛЬ', 'МУЛЬТИКОВ'), ('-ОНИ', 'СТОЯТ'), ('-Олесь', '-Пошёл'), ('-Песня', 'грусная='), ('-Плохое', 'пищеварение'), ('-Поэзия', 'заключает'), ('-ПриФетиГг', 'СолНыСко='), ('-Рыбу', 'соленую'), ('-СЕРЫЕ', '-ВРАЧ'), ('-Серые', '-НЕМЕЦКИЕ'), ('-Танцы', '-Хорошие'), ('-Ти', 'кантужена'), ('-Тиць', 'дурне'), ('-Трахався', '-Іди'), ('-ШАПКА', '-ФОН'), ('-Школа', '-Плохие'), ('-Юлия', 'Зазулина'), ('-Я.банан', '-ахх'), ('-анал', '-абстиненция'), ('-анатолий', 'николаевич'), ('-водичку', 'лью'), ('-г', 'үзээ'), ('-говорит', 'одноногий'), ('-дирекшионер', '-one'), ('-иногда', '.Ностальгирую'), ('-киллджой', '-шатенка'), ('-крутенько', '-выйду'), ('-купи', 'куру'), ('-кучи', 'мутики'), ('-ладно', '-АХАХАХАХХАХАХАХАХАХХА'), ('-ложусь', 'спать-темно'), ('-любому', 'умрёшь'), ('-место', '-кровать'), ('-напиши', '-нит'), ('-наш', 'класс^^'), ('-пиздишь', '-отвечаю'), ('-пиши', 'Ненси'), ('-попробуй', 'помедитировать'), ('-раз', 'плёткой'), ('-раздевайся', '-дак'), ('-распускаю', 'волосы-'), ('-руу', 'орох'), ('-рцензию', 'десятилетия'), ('-рүү', 'мэншндсэн'), ('-скоро', 'зароются'), ('-случайные', 'вопросы-'), ('-спрашивает', 'жена.-У'), ('-такое', 'ВЧ-8='), ('-указуказуказуказуа', '-материшся'), ('-хаски', '-розовое'), ('-хор', '-найл'), ('-хуи', 'сосешь'), ('-цвета', 'Магнита'), ('-цытата', 'Шимы'), ('-черные', '-аниме'), ('-шапку', '-фон'), ('-ынхаа', 'кодын'), ('-эртага', 'бозорга'), ('-юн', '-юп'), ('-юп', '-шапку'), ('.NET', 'языки.'), ('.Вот', 'кошмар-то'), ('.Вы', 'ахуеете'), ('.Прозвучало', 'неубедительно.Учитель'), ('.Спасибо', 'Бердянску'), ('.Хочу', 'миксануть'), ('.всё', 'неполноценность.я'), ('.выражаешься', '.то')]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk import collocations \n",
    "nltk.download('genesis')\n",
    "\n",
    "print(type(nltk.corpus.genesis.words('english-web.txt')))\n",
    "bigram_measures = collocations.BigramAssocMeasures()\n",
    "# bigram_finder.apply_freq_filter(5)\n",
    "bigram_finder = collocations.BigramCollocationFinder.from_documents([nltk.word_tokenize(x) for x in x_train])\n",
    "bigrams = bigram_finder.nbest(bigram_measures.pmi, 100)\n",
    "print(bigrams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_h4Cq1PUTTc-"
   },
   "source": [
    "Можно рассмотреть другие метрики оценки важности биграмм, например, метрику правдоподобия (подробнее про вычисление метрики можно посмотреть [здесь (пункт 5.3.4)](http://www.corpus.unam.mx/cursoenah/ManningSchutze_1999_FoundationsofStatisticalNaturalLanguageProcessing.pdf):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lTOJg4KoOo84",
    "outputId": "45d38953-84e0-4a65-fccd-1e96fd83c3f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('(', '('), ('RT', '@'), (')', ')'), ('http', ':'), ('!', '!'), (':', 'D'), ('у', 'меня'), (':', '('), (',', 'а'), (',', 'что'), (',', 'но'), (')', 'http'), ('*', '*'), (':', ')'), ('у', 'нас'), ('(', ','), ('не', 'могу'), (':', '-'), (',', '('), (',', ')'), ('?', '?'), (')', ','), (',', ':'), ('@', '('), (',', ','), (':', ','), ('(', ':'), ('@', ')'), ('@', ','), ('&', 'lt'), ('со', 'мной'), ('@', ':'), ('(', '@'), (';', ')'), (':', ':'), ('новый', 'год'), ('gt', ';'), (':', '*'), (')', ':'), (',', '@'), ('не', 'знаю'), ('У', 'меня'), ('@', '@'), ('а', 'я'), ('потому', 'что'), (',', 'когда'), ('сих', 'пор'), ('lt', ';'), ('у', 'тебя'), ('&', 'gt'), ('с', 'тобой'), (';', '('), ('все', 'равно'), ('в', 'школу'), (',', 'как'), ('(', 'http'), ('&', 'amp'), ('ничего', 'не'), (')', '@'), ('-', ')'), ('Как', 'же'), (',', 'я'), ('я', 'не'), (':', 'DD'), ('Доброе', 'утро'), ('не', '('), ('самом', 'деле'), ('до', 'сих'), ('не', ')'), ('amp', ';'), ('что', 'я'), (',', 'чтобы'), ('--', '--'), (',', '!'), ('как', 'же'), ('(', '!'), ('D', 'http'), ('не', ':'), ('никто', 'не'), ('с', 'кем'), ('=', ')'), ('и', '('), ('!', ','), ('.', 'А'), (':', '!'), ('об', 'этом'), ('?', '—'), ('а', 'потом'), (':', '|'), ('никогда', 'не'), (',', '.'), ('.', ','), ('Новый', 'Год'), ('@', 'не'), ('.', 'Но'), ('не', '@'), ('не', 'хочу'), (':', '.'), ('в', ','), ('=', '(')]\n"
     ]
    }
   ],
   "source": [
    "bigrams = bigram_finder.nbest(bigram_measures.likelihood_ratio, 100)\n",
    "print(bigrams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NfjCYZa8TeX_"
   },
   "source": [
    "Как можно заметить, немаловажную роль в текстах занимает пунктуация."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5AJk1B39LVRP"
   },
   "source": [
    "## Стоп-слова и пунктуация\n",
    "\n",
    "*Стоп-слова* -- это слова, которые часто встречаются практически в любом тексте и ничего интересного не говорят о конретном документе, то есть играют роль шума. Поэтому их принято убирать. По той же причине убирают и пунктуацию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fpWhsTuRLVRP",
    "outputId": "1cd18efe-a3cd-4f56-ec4c-bec8b6ee442e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Илья\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['и', 'в', 'во', 'не', 'что', 'он', 'на', 'я', 'с', 'со', 'как', 'а', 'то', 'все', 'она', 'так', 'его', 'но', 'да', 'ты', 'к', 'у', 'же', 'вы', 'за', 'бы', 'по', 'только', 'ее', 'мне', 'было', 'вот', 'от', 'меня', 'еще', 'нет', 'о', 'из', 'ему', 'теперь', 'когда', 'даже', 'ну', 'вдруг', 'ли', 'если', 'уже', 'или', 'ни', 'быть', 'был', 'него', 'до', 'вас', 'нибудь', 'опять', 'уж', 'вам', 'ведь', 'там', 'потом', 'себя', 'ничего', 'ей', 'может', 'они', 'тут', 'где', 'есть', 'надо', 'ней', 'для', 'мы', 'тебя', 'их', 'чем', 'была', 'сам', 'чтоб', 'без', 'будто', 'чего', 'раз', 'тоже', 'себе', 'под', 'будет', 'ж', 'тогда', 'кто', 'этот', 'того', 'потому', 'этого', 'какой', 'совсем', 'ним', 'здесь', 'этом', 'один', 'почти', 'мой', 'тем', 'чтобы', 'нее', 'сейчас', 'были', 'куда', 'зачем', 'всех', 'никогда', 'можно', 'при', 'наконец', 'два', 'об', 'другой', 'хоть', 'после', 'над', 'больше', 'тот', 'через', 'эти', 'нас', 'про', 'всего', 'них', 'какая', 'много', 'разве', 'три', 'эту', 'моя', 'впрочем', 'хорошо', 'свою', 'этой', 'перед', 'иногда', 'лучше', 'чуть', 'том', 'нельзя', 'такой', 'им', 'более', 'всегда', 'конечно', 'всю', 'между']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "# у вас здесь, вероятно, выскочит ошибка и надо будет загрузить стоп слова (в тексте ошибки написано, как)\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "print(stopwords.words('russian'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "OdRF7rlyLVRS",
    "outputId": "dd4ce4f0-13d0-4b21-a3a1-b9ecb281894f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from string import punctuation\n",
    "punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "OfXiH98XLVRV"
   },
   "outputs": [],
   "source": [
    "noise = stopwords.words('russian') + list(punctuation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KtiIhHDMLVRY"
   },
   "source": [
    "В векторизаторах за стоп-слова, логичным образом, отвечает аргумент `stop_words`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IZnbarm_LVRY",
    "outputId": "88f40278-165a-46ad-a75e-2e5d8e7e3a4d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:383: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "C:\\Users\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.77      0.78     29075\n",
      "    positive       0.76      0.79      0.78     27634\n",
      "\n",
      "    accuracy                           0.78     56709\n",
      "   macro avg       0.78      0.78      0.78     56709\n",
      "weighted avg       0.78      0.78      0.78     56709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "# nltk.download('punkt')\n",
    "vec = CountVectorizer(ngram_range=(1, 1), tokenizer=word_tokenize, stop_words=noise)\n",
    "bow = vec.fit_transform(x_train)\n",
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(bow, y_train)\n",
    "pred = clf.predict(vec.transform(x_test))\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wr934O7yLVRb"
   },
   "source": [
    "Получилось чууть лучше. Что ещё можно сделать?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D7O_oD1fLVRc"
   },
   "source": [
    "## Лемматизация\n",
    "\n",
    "Лемматизация – это сведение разных форм одного слова к начальной форме – *лемме*. Почему это хорошо?\n",
    "* Во-первых, мы хотим рассматривать как отдельную фичу каждое *слово*, а не каждую его отдельную форму.\n",
    "* Во-вторых, некоторые стоп-слова стоят только в начальной форме, и без лематизации выкидываем мы только её.\n",
    "\n",
    "Для русского есть два хороших лемматизатора: mystem и pymorphy:\n",
    "\n",
    "### [Mystem](https://tech.yandex.ru/mystem/)\n",
    "Как с ним работать:\n",
    "* можно скачать mystem и запускать [из терминала с разными параметрами](https://tech.yandex.ru/mystem/doc/)\n",
    "* [pymystem3](https://pythonhosted.org/pymystem3/pymystem3.html) - обертка для питона, работает медленнее, но это удобно"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "96HdoB7zLVRc",
    "outputId": "987397bc-55cb-4830-c361-5568f1f2e015"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-09-09 13:19:45--  http://download.cdn.yandex.net/mystem/mystem-3.0-linux3.1-64bit.tar.gz\n",
      "Resolving download.cdn.yandex.net (download.cdn.yandex.net)... 5.45.205.244, 5.45.205.243, 5.45.205.245, ...\n",
      "Connecting to download.cdn.yandex.net (download.cdn.yandex.net)|5.45.205.244|:80... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://cachev2-spb03.cdn.yandex.net/download.cdn.yandex.net/mystem/mystem-3.0-linux3.1-64bit.tar.gz?lid=122 [following]\n",
      "--2021-09-09 13:19:46--  https://cachev2-spb03.cdn.yandex.net/download.cdn.yandex.net/mystem/mystem-3.0-linux3.1-64bit.tar.gz?lid=122\n",
      "Resolving cachev2-spb03.cdn.yandex.net (cachev2-spb03.cdn.yandex.net)... 37.140.137.3, 2a02:6b8:0:2221::303\n",
      "Connecting to cachev2-spb03.cdn.yandex.net (cachev2-spb03.cdn.yandex.net)|37.140.137.3|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 16457938 (16M) [application/octet-stream]\n",
      "Saving to: ‘mystem-3.0-linux3.1-64bit.tar.gz.1’\n",
      "\n",
      "mystem-3.0-linux3.1 100%[===================>]  15.70M  9.80MB/s    in 1.6s    \n",
      "\n",
      "2021-09-09 13:19:49 (9.80 MB/s) - ‘mystem-3.0-linux3.1-64bit.tar.gz.1’ saved [16457938/16457938]\n",
      "\n",
      "mystem\n"
     ]
    }
   ],
   "source": [
    "!wget http://download.cdn.yandex.net/mystem/mystem-3.0-linux3.1-64bit.tar.gz\n",
    "!tar -xvf mystem-3.0-linux3.1-64bit.tar.gz\n",
    "!cp mystem /bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kzQwGwAaZWV5"
   },
   "outputs": [],
   "source": [
    "from pymystem3 import Mystem\n",
    "mystem_analyzer = Mystem()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_w-_fkNtLVRf"
   },
   "source": [
    "Мы инициализировали Mystem c дефолтными параметрами. А вообще параметры есть такие:\n",
    "* mystem_bin - путь к `mystem`, если их несколько\n",
    "* grammar_info - нужна ли грамматическая информация или только леммы (по дефолту нужна)\n",
    "* disambiguation - нужно ли снятие омонимии - дизамбигуация (по дефолту нужна)\n",
    "* entire_input - нужно ли сохранять в выводе все (пробелы всякие, например), или можно выкинуть (по дефолту оставляется все)\n",
    "\n",
    "Методы Mystem принимают строку, токенизатор вшит внутри. Можно, конечно, и пословно анализировать, но тогда он не сможет учитывать контекст.\n",
    "\n",
    "Можно просто лемматизировать текст:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fjHHLQv9txDq",
    "outputId": "35bcb3cc-7853-48bf-d38d-04157f45221d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['но', ' ', 'не', ' ', 'каждый', ' ', 'хотеть', ' ', 'что-то', ' ', 'исправлять', ':(\\n']\n"
     ]
    }
   ],
   "source": [
    "print(mystem_analyzer.lemmatize(example))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RI1eftjkLVRi"
   },
   "source": [
    "А можно получить грамматическую информацию:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j4MLqlZnxNEj",
    "outputId": "ffb676bb-932e-4579-817a-c15616431521"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'analysis': [{'gr': 'CONJ=', 'lex': 'но', 'wt': 0.9998906255}],\n",
       "  'text': 'Но'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'gr': 'PART=', 'lex': 'не', 'wt': 1}], 'text': 'не'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'gr': 'APRO=(вин,ед,муж,неод|им,ед,муж)',\n",
       "    'lex': 'каждый',\n",
       "    'wt': 0.9985975623}],\n",
       "  'text': 'каждый'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'gr': 'V,несов,пе=непрош,ед,изъяв,3-л',\n",
       "    'lex': 'хотеть',\n",
       "    'wt': 1}],\n",
       "  'text': 'хочет'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'gr': 'SPRO,ед,сред,неод=(вин|им)', 'lex': 'что-то', 'wt': 1}],\n",
       "  'text': 'что-то'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'gr': 'V,пе=инф,несов', 'lex': 'исправлять', 'wt': 1}],\n",
       "  'text': 'исправлять'},\n",
       " {'text': ':(\\n'}]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mystem_analyzer.analyze(example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ADcGtz4JLVRl"
   },
   "source": [
    "Давайте терепь используем лемматизатор майстема в качестве токенизатора."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x48Q56tiLVRn"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def my_preproc(text):\n",
    "    text = re.sub('[{}]'.format(punctuation), '', text)\n",
    "    text = mystem_analyzer.lemmatize(text)\n",
    "    return [word for word in text if word not in stopwords.words('russian') + [' ', '\\n']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wEwOQTJPLVRq",
    "outputId": "b1047a05-9fa7-4994-c947-578cfc4d9825"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.74      0.76     29425\n",
      "    positive       0.73      0.77      0.75     27284\n",
      "\n",
      "    accuracy                           0.75     56709\n",
      "   macro avg       0.75      0.75      0.75     56709\n",
      "weighted avg       0.75      0.75      0.75     56709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vec = CountVectorizer(ngram_range=(1, 1), tokenizer=my_preproc)\n",
    "bow = vec.fit_transform(x_train)\n",
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(bow, y_train)\n",
    "pred = clf.predict(vec.transform(x_test))\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RJlvqWuALVRs"
   },
   "source": [
    "### [Pymorphy](http://pymorphy2.readthedocs.io/en/latest/)\n",
    "Это модуль на питоне, довольно быстрый и с кучей функций."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tHDkurN1zf7g",
    "outputId": "c9934446-bf72-4603-8a51-9f6ebf406e44"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pymorphy2\n",
      "  Downloading pymorphy2-0.9.1-py3-none-any.whl (55 kB)\n",
      "\u001b[?25l\r",
      "\u001b[K     |██████                          | 10 kB 23.5 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▉                    | 20 kB 25.8 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▊              | 30 kB 12.2 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▋        | 40 kB 9.6 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▌  | 51 kB 4.9 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 55 kB 1.9 MB/s \n",
      "\u001b[?25hRequirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.7/dist-packages (from pymorphy2) (0.6.2)\n",
      "Collecting dawg-python>=0.7.1\n",
      "  Downloading DAWG_Python-0.7.2-py2.py3-none-any.whl (11 kB)\n",
      "Collecting pymorphy2-dicts-ru<3.0,>=2.4\n",
      "  Downloading pymorphy2_dicts_ru-2.4.417127.4579844-py2.py3-none-any.whl (8.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 8.2 MB 10.7 MB/s \n",
      "\u001b[?25hInstalling collected packages: pymorphy2-dicts-ru, dawg-python, pymorphy2\n",
      "Successfully installed dawg-python-0.7.2 pymorphy2-0.9.1 pymorphy2-dicts-ru-2.4.417127.4579844\n"
     ]
    }
   ],
   "source": [
    "!pip install pymorphy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymorphy2 import MorphAnalyzer\n",
    "pymorphy2_analyzer = MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qaz0x7frLVRw"
   },
   "source": [
    "pymorphy2 работает с отдельными словами. Если дать ему на вход предложение - он его просто не лемматизирует, т.к. не понимает"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jdf6XoEbLVRw",
    "outputId": "a1984e06-dbeb-4377-896d-b7014b6b84c1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parse(word='платили', tag=OpencorporaTag('VERB,impf,tran plur,past,indc'), normal_form='платить', score=1.0, methods_stack=((DictionaryAnalyzer(), 'платили', 2472, 10),))]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ana = pymorphy2_analyzer.parse(sent[3])\n",
    "ana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "0KuHQGPgLVRz",
    "outputId": "3cdbe79d-ec3f-4a07-ff3a-52e8810face1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'платить'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ana[0].normal_form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gg0EASPcLVR8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gFTkF8xUARlS"
   },
   "source": [
    "### [Natasha](https://github.com/natasha/)\n",
    "\n",
    "В библиотеке natasha реализовано множество полезных библиотек для русского языка: разбиение на токены и предложения, русскоязычные word embeddings, морфологический, синтаксический анализ, лемматизация, извлечение именованных сущностей и т.д. Модуль библиотеки Razdel, основанный на правилах, предназначен для разбиения текста на токены и предложения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-CVeDxeIA6rg",
    "outputId": "ff583009-ae7a-4b68-b6a7-ca1ba48c0732"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting razdel\n",
      "  Downloading razdel-0.5.0-py3-none-any.whl (21 kB)\n",
      "Installing collected packages: razdel\n",
      "Successfully installed razdel-0.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install razdel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MOTkw9MpAnNN",
    "outputId": "51fc6e54-3b82-4c1c-91c2-5b6a60f6304f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Substring(0, 13, 'Кружка-термос'),\n",
       " Substring(14, 16, 'на'),\n",
       " Substring(17, 20, '0.5'),\n",
       " Substring(20, 21, 'л'),\n",
       " Substring(22, 23, '('),\n",
       " Substring(23, 28, '50/64'),\n",
       " Substring(29, 32, 'см³'),\n",
       " Substring(32, 33, ','),\n",
       " Substring(34, 37, '516'),\n",
       " Substring(37, 38, ';'),\n",
       " Substring(38, 41, '...'),\n",
       " Substring(41, 42, ')')]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from razdel import tokenize\n",
    "\n",
    "tokens = list(tokenize('Кружка-термос на 0.5л (50/64 см³, 516;...)'))\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ftx-WzUbBCpO",
    "outputId": "40c67fa4-fab6-4c1b-f651-06951a38798e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Кружка-термос',\n",
       " 'на',\n",
       " '0.5',\n",
       " 'л',\n",
       " '(',\n",
       " '50/64',\n",
       " 'см³',\n",
       " ',',\n",
       " '516',\n",
       " ';',\n",
       " '...',\n",
       " ')']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[_.text for _ in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uyhsQp4MGbW8",
    "outputId": "55f84576-aaad-4a68-c5d9-38dc0ea2f721"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting natasha\n",
      "  Downloading natasha-1.4.0-py3-none-any.whl (34.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 34.4 MB 30 kB/s \n",
      "\u001b[?25hCollecting ipymarkup>=0.8.0\n",
      "  Downloading ipymarkup-0.9.0-py3-none-any.whl (14 kB)\n",
      "Collecting navec>=0.9.0\n",
      "  Downloading navec-0.10.0-py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: pymorphy2 in /usr/local/lib/python3.7/dist-packages (from natasha) (0.9.1)\n",
      "Collecting yargy>=0.14.0\n",
      "  Downloading yargy-0.15.0-py3-none-any.whl (41 kB)\n",
      "\u001b[K     |████████████████████████████████| 41 kB 102 kB/s \n",
      "\u001b[?25hCollecting slovnet>=0.3.0\n",
      "  Downloading slovnet-0.5.0-py3-none-any.whl (49 kB)\n",
      "\u001b[K     |████████████████████████████████| 49 kB 4.0 MB/s \n",
      "\u001b[?25hRequirement already satisfied: razdel>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from natasha) (0.5.0)\n",
      "Collecting intervaltree>=3\n",
      "  Downloading intervaltree-3.1.0.tar.gz (32 kB)\n",
      "Requirement already satisfied: sortedcontainers<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from intervaltree>=3->ipymarkup>=0.8.0->natasha) (2.4.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from navec>=0.9.0->natasha) (1.19.5)\n",
      "Requirement already satisfied: dawg-python>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from pymorphy2->natasha) (0.7.2)\n",
      "Requirement already satisfied: pymorphy2-dicts-ru<3.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from pymorphy2->natasha) (2.4.417127.4579844)\n",
      "Requirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.7/dist-packages (from pymorphy2->natasha) (0.6.2)\n",
      "Building wheels for collected packages: intervaltree\n",
      "  Building wheel for intervaltree (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for intervaltree: filename=intervaltree-3.1.0-py2.py3-none-any.whl size=26119 sha256=c21bb14c19f5774a60e5bb5d903ac3f80d37a2760af69683789029fcfa71fc54\n",
      "  Stored in directory: /root/.cache/pip/wheels/16/85/bd/1001cbb46dcfb71c2001cd7401c6fb250392f22a81ce3722f7\n",
      "Successfully built intervaltree\n",
      "Installing collected packages: navec, intervaltree, yargy, slovnet, ipymarkup, natasha\n",
      "  Attempting uninstall: intervaltree\n",
      "    Found existing installation: intervaltree 2.1.0\n",
      "    Uninstalling intervaltree-2.1.0:\n",
      "      Successfully uninstalled intervaltree-2.1.0\n",
      "Successfully installed intervaltree-3.1.0 ipymarkup-0.9.0 natasha-1.4.0 navec-0.10.0 slovnet-0.5.0 yargy-0.15.0\n"
     ]
    }
   ],
   "source": [
    "!pip install natasha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jMO3jsqLKSIV"
   },
   "source": [
    "С помощью библиотеки natasha можно также лемматизировать тексты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "vJZgfRnvIS2q"
   },
   "outputs": [],
   "source": [
    "from natasha import Doc, MorphVocab, Segmenter, NewsEmbedding, NewsMorphTagger\n",
    "\n",
    "segmenter = Segmenter()\n",
    "morph_vocab = MorphVocab()\n",
    "emb = NewsEmbedding()\n",
    "morph_tagger = NewsMorphTagger(emb)\n",
    "\n",
    "def natasha_lemmatize(text):\n",
    "    doc = Doc(text)\n",
    "    doc.segment(segmenter)\n",
    "    doc.tag_morph(morph_tagger)\n",
    "    for token in doc.tokens:\n",
    "        token.lemmatize(morph_vocab)\n",
    "    return {_.text: _.lemma for _ in doc.tokens}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iBtlnYlFBOKv",
    "outputId": "47a9e7d6-7f03-4e93-e57c-84dce5657d97"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Посол': 'посол',\n",
       " 'Израиля': 'израиль',\n",
       " 'на': 'на',\n",
       " 'Украине': 'украина',\n",
       " 'Йоэль': 'йоэль',\n",
       " 'Лион': 'лион',\n",
       " 'признался': 'признаться',\n",
       " ',': ',',\n",
       " 'что': 'что',\n",
       " 'пришел': 'прийти',\n",
       " 'в': 'в',\n",
       " 'шок': 'шок',\n",
       " 'узнав': 'узнать',\n",
       " 'о': 'о',\n",
       " 'решении': 'решение',\n",
       " 'властей': 'власть',\n",
       " 'Львовской': 'львовский',\n",
       " 'области': 'область',\n",
       " 'объявить': 'объявить',\n",
       " '2019': '2019',\n",
       " 'год': 'год',\n",
       " 'годом': 'год',\n",
       " 'лидера': 'лидер',\n",
       " 'запрещенной': 'запретить',\n",
       " 'России': 'россия',\n",
       " 'Организации': 'организация',\n",
       " 'украинских': 'украинский',\n",
       " 'националистов': 'националист',\n",
       " '(': '(',\n",
       " 'ОУН': 'оун',\n",
       " ')': ')',\n",
       " 'Степана': 'степан',\n",
       " 'Бандеры': 'бандера',\n",
       " '.': '.',\n",
       " 'Свое': 'свой',\n",
       " 'заявление': 'заявление',\n",
       " 'он': 'он',\n",
       " 'разместил': 'разместить',\n",
       " 'Twitter': 'twitter',\n",
       " '«': '«',\n",
       " 'Я': 'я',\n",
       " 'не': 'не',\n",
       " 'могу': 'мочь',\n",
       " 'понять': 'понять',\n",
       " 'как': 'как',\n",
       " 'прославление': 'прославление',\n",
       " 'тех': 'тот',\n",
       " 'кто': 'кто',\n",
       " 'непосредственно': 'непосредственно',\n",
       " 'принимал': 'принимать',\n",
       " 'участие': 'участие',\n",
       " 'ужасных': 'ужасный',\n",
       " 'антисемитских': 'антисемитский',\n",
       " 'преступлениях': 'преступление',\n",
       " 'помогает': 'помогать',\n",
       " 'бороться': 'бороться',\n",
       " 'с': 'с',\n",
       " 'антисемитизмом': 'антисемитизм',\n",
       " 'и': 'и',\n",
       " 'ксенофобией': 'ксенофобия',\n",
       " 'Украина': 'украина',\n",
       " 'должна': 'должный',\n",
       " 'забывать': 'забывать',\n",
       " 'совершенных': 'совершить',\n",
       " 'против': 'против',\n",
       " 'евреев': 'еврей',\n",
       " 'никоим': 'никой',\n",
       " 'образом': 'образ',\n",
       " 'отмечать': 'отмечать',\n",
       " 'их': 'они',\n",
       " 'через': 'через',\n",
       " 'почитание': 'почитание',\n",
       " 'исполнителей': 'исполнитель',\n",
       " '»': '»',\n",
       " '—': '—',\n",
       " 'написал': 'написать',\n",
       " 'дипломат': 'дипломат',\n",
       " '11': '11',\n",
       " 'декабря': 'декабрь',\n",
       " 'Львовский': 'львовский',\n",
       " 'областной': 'областной',\n",
       " 'совет': 'совет',\n",
       " 'принял': 'принять',\n",
       " 'решение': 'решение',\n",
       " 'провозгласить': 'провозгласить',\n",
       " 'регионе': 'регион',\n",
       " 'связи': 'связь',\n",
       " 'празднованием': 'празднование',\n",
       " '110-летия': '110-летие',\n",
       " 'со': 'с',\n",
       " 'дня': 'день',\n",
       " 'рождения': 'рождение',\n",
       " 'Бандера': 'бандера',\n",
       " 'родился': 'родиться',\n",
       " '1': '1',\n",
       " 'января': 'январь',\n",
       " '1909': '1909',\n",
       " 'года': 'год',\n",
       " 'В': 'в',\n",
       " 'июле': 'июль',\n",
       " 'аналогичное': 'аналогичный',\n",
       " 'Житомирский': 'житомирский',\n",
       " 'начале': 'начало',\n",
       " 'месяца': 'месяц',\n",
       " 'предложением': 'предложение',\n",
       " 'к': 'к',\n",
       " 'президенту': 'президент',\n",
       " 'страны': 'страна',\n",
       " 'Петру': 'петр',\n",
       " 'Порошенко': 'порошенко',\n",
       " 'вернуть': 'вернуть',\n",
       " 'Бандере': 'бандера',\n",
       " 'звание': 'звание',\n",
       " 'Героя': 'герой',\n",
       " 'Украины': 'украина',\n",
       " 'обратились': 'обратиться',\n",
       " 'депутаты': 'депутат',\n",
       " 'Верховной': 'верховный',\n",
       " 'Рады': 'рада',\n",
       " 'Парламентарии': 'парламентарий',\n",
       " 'уверены': 'уверить',\n",
       " 'признание': 'признание',\n",
       " 'национальным': 'национальный',\n",
       " 'героем': 'герой',\n",
       " 'поможет': 'помочь',\n",
       " 'борьбе': 'борьба',\n",
       " 'подрывной': 'подрывной',\n",
       " 'деятельностью': 'деятельность',\n",
       " 'информационном': 'информационный',\n",
       " 'поле': 'поле',\n",
       " 'а': 'а',\n",
       " 'также': 'также',\n",
       " 'остановит': 'остановить',\n",
       " 'распространение': 'распространение',\n",
       " 'мифов': 'миф',\n",
       " 'созданных': 'создать',\n",
       " 'российской': 'российский',\n",
       " 'пропагандой': 'пропаганда',\n",
       " 'Степан': 'степан',\n",
       " '1909-1959': '1909-1959',\n",
       " 'был': 'быть',\n",
       " 'одним': 'один',\n",
       " 'из': 'из',\n",
       " 'лидеров': 'лидер',\n",
       " 'выступающей': 'выступать',\n",
       " 'за': 'за',\n",
       " 'создание': 'создание',\n",
       " 'независимого': 'независимый',\n",
       " 'государства': 'государство',\n",
       " 'территориях': 'территория',\n",
       " 'украиноязычным': 'украиноязычный',\n",
       " 'населением': 'население',\n",
       " '2010': '2010',\n",
       " 'году': 'год',\n",
       " 'период': 'период',\n",
       " 'президентства': 'президентство',\n",
       " 'Виктора': 'виктор',\n",
       " 'Ющенко': 'ющенко',\n",
       " 'посмертно': 'посмертно',\n",
       " 'признан': 'признать',\n",
       " 'Героем': 'герой',\n",
       " 'однако': 'однако',\n",
       " 'впоследствии': 'впоследствии',\n",
       " 'это': 'это',\n",
       " 'было': 'быть',\n",
       " 'отменено': 'отменить',\n",
       " 'судом': 'суд'}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'Посол Израиля на Украине Йоэль Лион признался, что пришел в шок, узнав о решении властей Львовской области объявить 2019 год годом лидера запрещенной в России Организации украинских националистов (ОУН) Степана Бандеры. Свое заявление он разместил в Twitter. «Я не могу понять, как прославление тех, кто непосредственно принимал участие в ужасных антисемитских преступлениях, помогает бороться с антисемитизмом и ксенофобией. Украина не должна забывать о преступлениях, совершенных против украинских евреев, и никоим образом не отмечать их через почитание их исполнителей», — написал дипломат. 11 декабря Львовский областной совет принял решение провозгласить 2019 год в регионе годом Степана Бандеры в связи с празднованием 110-летия со дня рождения лидера ОУН (Бандера родился 1 января 1909 года). В июле аналогичное решение принял Житомирский областной совет. В начале месяца с предложением к президенту страны Петру Порошенко вернуть Бандере звание Героя Украины обратились депутаты Верховной Рады. Парламентарии уверены, что признание Бандеры национальным героем поможет в борьбе с подрывной деятельностью против Украины в информационном поле, а также остановит «распространение мифов, созданных российской пропагандой». Степан Бандера (1909-1959) был одним из лидеров Организации украинских националистов, выступающей за создание независимого государства на территориях с украиноязычным населением. В 2010 году в период президентства Виктора Ющенко Бандера был посмертно признан Героем Украины, однако впоследствии это решение было отменено судом. '\n",
    "\n",
    "natasha_lemmatize(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rck5OVqhLVSA"
   },
   "source": [
    "### mystem vs. pymorphy vs. natasha\n",
    "\n",
    "1) *Мы надеемся, что вы пользуетесь линуксом*, но mystem работает невероятно медленно под windows на больших текстах.\n",
    "\n",
    "2) *Снятие омонимии*. Mystem умеет снимать омонимию по контексту (хотя не всегда преуспевает), pymorphy2 берет на вход одно слово и соответственно вообще не умеет дизамбигуировать по контексту, natasha тоже с этим тоже не справляется успешно:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "kH2GQ4ddLVSB"
   },
   "outputs": [],
   "source": [
    "homonym1 = 'За время обучения я прослушал больше сорока курсов.'\n",
    "homonym2 = 'Сорока своровала блестящее украшение со стола.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WwF-XsjeI3eX",
    "outputId": "34e9f131-3af5-4a87-9a8c-aa51d6e076ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'analysis': [{'lex': 'сорок', 'wt': 0.8710292578, 'gr': 'NUM=(пр|дат|род|твор)'}], 'text': 'сорока'}\n",
      "{'analysis': [{'lex': 'сорока', 'wt': 0.1210970059, 'gr': 'S,жен,од=им,ед'}], 'text': 'Сорока'}\n"
     ]
    }
   ],
   "source": [
    "mystem_analyzer = Mystem() # инициализирую объект с дефолтными параметрами\n",
    "\n",
    "print(mystem_analyzer.analyze(homonym1)[-5])\n",
    "print(mystem_analyzer.analyze(homonym2)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t9jezRVlFmDo",
    "outputId": "e2224fd9-09e3-428e-fa6a-1af94dcb2ca8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'За': 'за', 'время': 'время', 'обучения': 'обучение', 'я': 'я', 'прослушал': 'прослушать', 'больше': 'большой', 'сорока': 'сорок', 'курсов': 'курс', '.': '.'}\n"
     ]
    }
   ],
   "source": [
    "print(natasha_lemmatize(homonym1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SXjGBQPoI9gl",
    "outputId": "049fe8af-e0c5-499f-cc10-6d05b047a168"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Сорока': 'сорок', 'своровала': 'своровать', 'блестящее': 'блестящий', 'украшение': 'украшение', 'со': 'с', 'стола': 'стол', '.': '.'}\n"
     ]
    }
   ],
   "source": [
    "print(natasha_lemmatize(homonym2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aP5qFnilLVSI"
   },
   "source": [
    "## Словарь, закон Ципфа и закон Хипса"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s1umtd3OLVSI"
   },
   "source": [
    "Закон Ципфа -- эмпирическая закономерность: если все слова корпуса текста упорядочить по убыванию частоты их использования, то частота n-го слова в таком списке окажется приблизительно обратно пропорциональной его порядковому номеру n. Иными словами, частотность слов убывает очень быстро."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "lY0cWJ7eLVSJ"
   },
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vIjqSVjpLVSL",
    "outputId": "a75ec748-ab21-4bd0-cd41-5a9fa8362b22"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2870536\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['first_timee', 'хоть', 'я', 'и', 'школота', 'но', 'поверь', 'у', 'нас', 'то']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = [token for tweet in df.text for token in word_tokenize(tweet) if token not in punctuation]\n",
    "print(len(corpus))\n",
    "corpus[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "_oWC7NpkLVSO",
    "outputId": "965b9fbd-6328-4c13-f20f-cd3714d1adb4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('не', 69472),\n",
       " ('и', 55166),\n",
       " ('в', 52902),\n",
       " ('я', 52818),\n",
       " ('RT', 38070),\n",
       " ('на', 35759),\n",
       " ('http', 32998),\n",
       " ('что', 31541),\n",
       " ('с', 27217),\n",
       " ('а', 26860)]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_dict = Counter(corpus)\n",
    "freq_dict_sorted= sorted(freq_dict.items(), key=lambda x: -x[1])\n",
    "list(freq_dict_sorted)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "FrPkce0SLVSQ",
    "outputId": "d2ab5675-433a-480a-90ee-fa5dd9890922"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "first_100_freqs = [freq for word, freq in freq_dict_sorted[:100]]\n",
    "plt.plot(first_100_freqs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i_N5V_K-LVSU"
   },
   "source": [
    "Закон Хипса -- обратная сторона закона Ципфа. Он описывает, что чем больше корпус, тем меньше новых слов добавляется с добавлением новых текстов. В какой-то момент корпус насыщается."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dw0GieJSMU-O"
   },
   "source": [
    "## Задание 1.\n",
    "\n",
    "**Задание**: обучите три классификатора: \n",
    "\n",
    "1) на токенах с высокой частотой \n",
    "\n",
    "2) на токенах со средней частотой \n",
    "\n",
    "3) на токенах с низкой частотой\n",
    "\n",
    "Сравните полученные результаты, оцените какие токены наиболее важные для классификации."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, какой у нас размер словаря:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "QUQ6kAgPMqNn"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "351101"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(freq_dict_sorted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем просто поделить словарь на 3 части, и на каждой части обучится. Для того, чтобы остальные слова не входили в обучение, поместим их в стоп-слова:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_freq_tokens = [itm[0] for itm in freq_dict_sorted[:117033]]\n",
    "middle_freq_tokens = [itm[0] for itm in freq_dict_sorted[117033:234066]]\n",
    "low_freq_tokens = [itm[0] for itm in freq_dict_sorted[234066:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.77      0.78     28825\n",
      "    positive       0.77      0.79      0.78     27884\n",
      "\n",
      "    accuracy                           0.78     56709\n",
      "   macro avg       0.78      0.78      0.78     56709\n",
      "weighted avg       0.78      0.78      0.78     56709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vec = CountVectorizer(ngram_range=(1, 1), tokenizer=word_tokenize, stop_words=noise + middle_freq_tokens + low_freq_tokens)\n",
    "bow = vec.fit_transform(x_train)\n",
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(bow, y_train)\n",
    "pred = clf.predict(vec.transform(x_test))\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.54      0.68     48146\n",
      "    positive       0.23      0.78      0.36      8563\n",
      "\n",
      "    accuracy                           0.58     56709\n",
      "   macro avg       0.58      0.66      0.52     56709\n",
      "weighted avg       0.83      0.58      0.64     56709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vec = CountVectorizer(ngram_range=(1, 1), tokenizer=word_tokenize, stop_words=noise + high_freq_tokens + low_freq_tokens)\n",
    "bow = vec.fit_transform(x_train)\n",
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(bow, y_train)\n",
    "pred = clf.predict(vec.transform(x_test))\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.12      0.66      0.20      5113\n",
      "    positive       0.94      0.52      0.67     51596\n",
      "\n",
      "    accuracy                           0.53     56709\n",
      "   macro avg       0.53      0.59      0.44     56709\n",
      "weighted avg       0.86      0.53      0.63     56709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vec = CountVectorizer(ngram_range=(1, 1), tokenizer=word_tokenize, stop_words=noise + high_freq_tokens + middle_freq_tokens)\n",
    "bow = vec.fit_transform(x_train)\n",
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(bow, y_train)\n",
    "pred = clf.predict(vec.transform(x_test))\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видно, наиболее важными токенами для обучения являются частотные токены"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mV3fmzp-LVSU"
   },
   "source": [
    "## О важности эксплоративного анализа\n",
    "\n",
    "Но иногда пунктуация бывает и не шумом -- главное отталкиваться от задачи. Что будет если вообще не убирать пунктуацию?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "qjkMxK9VLVSV",
    "outputId": "dfea56d5-4d92-4862-9788-29c8c8db29ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00     27932\n",
      "    positive       1.00      1.00      1.00     28777\n",
      "\n",
      "    accuracy                           1.00     56709\n",
      "   macro avg       1.00      1.00      1.00     56709\n",
      "weighted avg       1.00      1.00      1.00     56709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vec = TfidfVectorizer(ngram_range=(1, 1), tokenizer=word_tokenize)\n",
    "bow = vec.fit_transform(x_train)\n",
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(bow, y_train)\n",
    "pred = clf.predict(vec.transform(x_test))\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w2fRbUAvLVSX"
   },
   "source": [
    "Шок! Стоило оставить пунктуацию -- и все метрики равны 1. Как это получилось? Среди неё были очень значимые токены (как вы думаете, какие?). Найдите фичи с самыми большими коэффициэнтами:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 2.\n",
    "\n",
    "найти фичи с наибольшей значимостью, и вывести их"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.02821407,  0.37364641, -0.11531882, ...,  0.00878569,\n",
       "         0.00610997,  0.00070052]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "id": "b_JRuyuRLVSY"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature name</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>)</td>\n",
       "      <td>58.464072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43441</th>\n",
       "      <td>d</td>\n",
       "      <td>26.898192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44849</th>\n",
       "      <td>dd</td>\n",
       "      <td>10.582249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29375</th>\n",
       "      <td>^_^</td>\n",
       "      <td>8.949486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44858</th>\n",
       "      <td>ddd</td>\n",
       "      <td>8.106151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>*</td>\n",
       "      <td>7.520177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>-d</td>\n",
       "      <td>7.262788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29276</th>\n",
       "      <td>:</td>\n",
       "      <td>5.717497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44860</th>\n",
       "      <td>dddd</td>\n",
       "      <td>4.773284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44861</th>\n",
       "      <td>ddddd</td>\n",
       "      <td>3.244524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163074</th>\n",
       "      <td>люблю</td>\n",
       "      <td>1.787136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29325</th>\n",
       "      <td>=^_^=</td>\n",
       "      <td>1.702293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44862</th>\n",
       "      <td>dddddd</td>\n",
       "      <td>1.626336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227809</th>\n",
       "      <td>спасибо</td>\n",
       "      <td>1.578948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247037</th>\n",
       "      <td>х</td>\n",
       "      <td>1.437745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106215</th>\n",
       "      <td>ахах</td>\n",
       "      <td>1.382915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106260</th>\n",
       "      <td>ахахах</td>\n",
       "      <td>1.326634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>%</td>\n",
       "      <td>1.288903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206827</th>\n",
       "      <td>приятно</td>\n",
       "      <td>1.236831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216631</th>\n",
       "      <td>рождения</td>\n",
       "      <td>1.234505</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       feature name  importance\n",
       "8                 )   58.464072\n",
       "43441             d   26.898192\n",
       "44849            dd   10.582249\n",
       "29375           ^_^    8.949486\n",
       "44858           ddd    8.106151\n",
       "9                 *    7.520177\n",
       "245              -d    7.262788\n",
       "29276             :    5.717497\n",
       "44860          dddd    4.773284\n",
       "44861         ddddd    3.244524\n",
       "163074        люблю    1.787136\n",
       "29325         =^_^=    1.702293\n",
       "44862        dddddd    1.626336\n",
       "227809      спасибо    1.578948\n",
       "247037            х    1.437745\n",
       "106215         ахах    1.382915\n",
       "106260       ахахах    1.326634\n",
       "3                 %    1.288903\n",
       "206827      приятно    1.236831\n",
       "216631     рождения    1.234505"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats_important_positive = pd.DataFrame(zip(vec.get_feature_names(), clf.coef_[0]), columns=['feature name', 'importance']).sort_values(by='importance', ascending=False).head(20)\n",
    "feats_important_positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature name</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(</td>\n",
       "      <td>-59.634706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101335</th>\n",
       "      <td>|</td>\n",
       "      <td>-11.131372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180082</th>\n",
       "      <td>о_о</td>\n",
       "      <td>-10.726111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77536</th>\n",
       "      <td>o_o</td>\n",
       "      <td>-8.758971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>-/</td>\n",
       "      <td>-8.640425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42360</th>\n",
       "      <td>cio_optimal</td>\n",
       "      <td>-5.514056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92716</th>\n",
       "      <td>to_over_kill</td>\n",
       "      <td>-5.439694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46629</th>\n",
       "      <td>do_or_die_xxx</td>\n",
       "      <td>-4.753814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84424</th>\n",
       "      <td>rt</td>\n",
       "      <td>-4.126589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83397</th>\n",
       "      <td>reno_oppa</td>\n",
       "      <td>-4.065795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81756</th>\n",
       "      <td>prisonero_o</td>\n",
       "      <td>-4.051122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54974</th>\n",
       "      <td>horanso_on</td>\n",
       "      <td>-3.496090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62762</th>\n",
       "      <td>kota_oo_oo</td>\n",
       "      <td>-2.982931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40217</th>\n",
       "      <td>boo_ohoo</td>\n",
       "      <td>-2.843002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30008</th>\n",
       "      <td>_do_or_die__</td>\n",
       "      <td>-2.783309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82666</th>\n",
       "      <td>radio_of_moon</td>\n",
       "      <td>-2.618956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225103</th>\n",
       "      <td>снаступающимтвиттерский</td>\n",
       "      <td>-2.584757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77542</th>\n",
       "      <td>o_obnulyay</td>\n",
       "      <td>-2.404734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67657</th>\n",
       "      <td>lponomarenko_o</td>\n",
       "      <td>-2.378007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59064</th>\n",
       "      <td>july_to_october</td>\n",
       "      <td>-2.223497</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   feature name  importance\n",
       "7                             (  -59.634706\n",
       "101335                        |  -11.131372\n",
       "180082                      о_о  -10.726111\n",
       "77536                       o_o   -8.758971\n",
       "133                          -/   -8.640425\n",
       "42360               cio_optimal   -5.514056\n",
       "92716              to_over_kill   -5.439694\n",
       "46629             do_or_die_xxx   -4.753814\n",
       "84424                        rt   -4.126589\n",
       "83397                 reno_oppa   -4.065795\n",
       "81756               prisonero_o   -4.051122\n",
       "54974                horanso_on   -3.496090\n",
       "62762                kota_oo_oo   -2.982931\n",
       "40217                  boo_ohoo   -2.843002\n",
       "30008              _do_or_die__   -2.783309\n",
       "82666             radio_of_moon   -2.618956\n",
       "225103  снаступающимтвиттерский   -2.584757\n",
       "77542                o_obnulyay   -2.404734\n",
       "67657            lponomarenko_o   -2.378007\n",
       "59064           july_to_october   -2.223497"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats_important_negative = pd.DataFrame(zip(vec.get_feature_names(), clf.coef_[0]), columns=['feature name', 'importance']).sort_values(by='importance', ascending=True).head(20)\n",
    "feats_important_negative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видим, самыми значимыми фичами для отнесения твита к позитивному или негативному являются смайлики ')' и '('"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8vtAyItvLVSb"
   },
   "source": [
    "Посмотрим, как один из супер-значительных токенов справится с классификацией безо всякого машинного обучения:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "id": "uqH07o-7LVSc",
    "outputId": "fad0a24a-98ee-4f84-8782-495548eb0fb4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.85      0.92     32901\n",
      "    positive       0.83      1.00      0.91     23808\n",
      "\n",
      "    accuracy                           0.91     56709\n",
      "   macro avg       0.91      0.93      0.91     56709\n",
      "weighted avg       0.93      0.91      0.91     56709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cool_token = ')'\n",
    "pred = ['positive' if cool_token in tweet else 'negative' for tweet in x_test]\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H5THCOjMLVSg"
   },
   "source": [
    "## Символьные n-граммы\n",
    "\n",
    "Теперь в качестве фичей используем, например, униграммы символов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AIUwDOabLVSh",
    "outputId": "54f129b1-994f-448e-e861-1912b4a21cdc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.99      1.00      1.00     27667\n",
      "   positive       1.00      0.99      1.00     29042\n",
      "\n",
      "avg / total       1.00      1.00      1.00     56709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vec = CountVectorizer(analyzer='char', ngram_range=(1, 1))\n",
    "bow = vec.fit_transform(x_train)\n",
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(bow, y_train)\n",
    "pred = clf.predict(vec.transform(x_test))\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z_E0uPpgLVSj"
   },
   "source": [
    "В общем-то, теперь уже понятно, почему на этих данных здесь 1. Так или инчае, на символах классифицировать тоже можно: для некторых задач (например, для определения языка) фичи-символьные n-граммы решительно рулят.\n",
    "\n",
    "Ещё одна замечательная особенность фичей-символов: токенизация и лемматизация не нужна, можно использовать такой подход для языков, у которых нет готвых анализаторов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Домашнее задание\n",
    "\n",
    "все материалы для выполения дз в `sem2.ipynb`\n",
    "\n",
    "\n",
    "### Задание 1.\n",
    "\n",
    "**Задание**: обучите три классификатора: \n",
    "\n",
    "1) на токенах с высокой частотой \n",
    "\n",
    "2) на токенах со средней частотой \n",
    "\n",
    "3) на токенах с низкой частотой\n",
    "\n",
    "\n",
    "Сравните полученные результаты, оцените какие токены наиболее важные для классификации.\n",
    "\n",
    "\n",
    "### Задание 2.\n",
    "\n",
    "найти фичи с наибольшей значимостью, и вывести их\n",
    "\n",
    "\n",
    "### Задание 3.\n",
    "\n",
    "1) сравнить count/tf-idf/hashing векторайзеры/полносвязанную сетку (построить classification_report)\n",
    "\n",
    "2) подобрать оптимальный размер для hashing векторайзера \n",
    "\n",
    "3) убедиться что для сетки нет переобучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00     27992\n",
      "    positive       1.00      1.00      1.00     28717\n",
      "\n",
      "    accuracy                           1.00     56709\n",
      "   macro avg       1.00      1.00      1.00     56709\n",
      "weighted avg       1.00      1.00      1.00     56709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# CountVectorizer\n",
    "vec = CountVectorizer(ngram_range=(1, 1), tokenizer=word_tokenize)\n",
    "bow = vec.fit_transform(x_train)\n",
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(bow, y_train)\n",
    "pred = clf.predict(vec.transform(x_test))\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00     27932\n",
      "    positive       1.00      1.00      1.00     28777\n",
      "\n",
      "    accuracy                           1.00     56709\n",
      "   macro avg       1.00      1.00      1.00     56709\n",
      "weighted avg       1.00      1.00      1.00     56709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TfidfVectorizer\n",
    "vec = TfidfVectorizer(ngram_range=(1, 1), tokenizer=word_tokenize)\n",
    "bow = vec.fit_transform(x_train)\n",
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(bow, y_train)\n",
    "pred = clf.predict(vec.transform(x_test))\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.96     27708\n",
      "    positive       0.96      0.95      0.96     29001\n",
      "\n",
      "    accuracy                           0.96     56709\n",
      "   macro avg       0.96      0.96      0.96     56709\n",
      "weighted avg       0.96      0.96      0.96     56709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# HashingVectorizer, n_features=100\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "\n",
    "vec = HashingVectorizer(n_features=100, ngram_range=(1, 1), tokenizer=word_tokenize)\n",
    "bow = vec.fit_transform(x_train)\n",
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(bow, y_train)\n",
    "pred = clf.predict(vec.transform(x_test))\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.94      0.93     27532\n",
      "    positive       0.94      0.93      0.94     29177\n",
      "\n",
      "    accuracy                           0.94     56709\n",
      "   macro avg       0.94      0.94      0.94     56709\n",
      "weighted avg       0.94      0.94      0.94     56709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# HashingVectorizer, n_features=50\n",
    "vec = HashingVectorizer(n_features=50, ngram_range=(1, 1), tokenizer=word_tokenize)\n",
    "bow = vec.fit_transform(x_train)\n",
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(bow, y_train)\n",
    "pred = clf.predict(vec.transform(x_test))\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.98      0.98      0.98     27858\n",
      "    positive       0.98      0.98      0.98     28851\n",
      "\n",
      "    accuracy                           0.98     56709\n",
      "   macro avg       0.98      0.98      0.98     56709\n",
      "weighted avg       0.98      0.98      0.98     56709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# HashingVectorizer, n_features=200\n",
    "vec = HashingVectorizer(n_features=200, ngram_range=(1, 1), tokenizer=word_tokenize)\n",
    "bow = vec.fit_transform(x_train)\n",
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(bow, y_train)\n",
    "pred = clf.predict(vec.transform(x_test))\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Эту работу я делал на локальной машине, часть с нейросетью же сделал в коллабе: https://colab.research.google.com/drive/1rCEecvNEmHm_P7EczHThKVi473XLdie2?usp=sharing\n",
    "\n",
    "Также можно посмотреть второй файл в репозитории с именем HW2_part2_NN.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Выводы**\n",
    "\n",
    "- CountVectorizer и TfidfVectorizer без обрезания пунктуации имеют лучшие результаты\n",
    "- HashingVectorizer имеет чуть худший результат.\n",
    "- Хуже всего справилась нейросеть - 82%"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "gJABxhalLVQu",
    "IaQMCGHFLVQ6",
    "5AJk1B39LVRP",
    "RJlvqWuALVRs",
    "rck5OVqhLVSA",
    "mV3fmzp-LVSU",
    "H5THCOjMLVSg",
    "02s2Vh7MLVSj",
    "b1khxRFDLVSm",
    "sfUmWcAQLVSt",
    "BxvtN-3zLVS5",
    "gyrHhYkgLVTB"
   ],
   "name": "sem1_intro_common.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
